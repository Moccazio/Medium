{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains information on downloading and saving data ready for zipline ingest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from time import sleep\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from time import time\n",
    "from datetime import datetime\n",
    "from pandas import Timestamp\n",
    "import datetime as dt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta, date\n",
    "from pandas.tseries.offsets import BDay\n",
    "from yahoofinancials import YahooFinancials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(df_data):\n",
    "    df_data.fillna(method='ffill', inplace=True)\n",
    "    df_data.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start and end dates \n",
    "end = date.today() - pd.tseries.offsets.BusinessDay(n = 1)\n",
    "start = end - 20 * 252 * pd.tseries.offsets.BDay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023-02-28'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2003-11-04'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data for Zipline Ingest\n",
    "\n",
    "we prepare the csv data for zipline ingest later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T07:53:26.537656Z",
     "start_time": "2022-11-21T07:53:26.518293Z"
    }
   },
   "outputs": [],
   "source": [
    "def download_csv_data(symbol, start_date, end_date, freq, path):\n",
    "    yf = YahooFinancials(symbol)\n",
    "    res = yf.get_historical_price_data(str(start_date), str(end_date),freq)\n",
    "    if not res or symbol not in res or 'prices' not in res[symbol]:\n",
    "        ValueError('Fetching price data for \"{}\" failed.'.format(symbol))\n",
    "    prices = res[symbol]['prices']\n",
    "    df = pd.DataFrame({'open': [p['open'] for p in prices],\n",
    "                       'high': [p['high'] for p in prices],\n",
    "                       'low': [p['low'] for p in prices],\n",
    "                       'close': [p['close'] for p in prices],\n",
    "                       'volume': [p['volume'] for p in prices],}, index=[pd.Timestamp(d['formatted_date']) for d in prices])\n",
    "    if 'dividend' in prices:\n",
    "        df['dividend'] = [p['dividend'] for p in prices]\n",
    "    else:\n",
    "        df['dividend'] = 0\n",
    "\n",
    "    if 'split' in prices:\n",
    "        df['split'] = [p['split'] for p in prices]\n",
    "    else:\n",
    "        df['split'] = 1\n",
    "    df.sort_index(inplace=True)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df.index = df.index.tz_localize('UTC').normalize()\n",
    "    df.index = df.index.strftime(\"%Y-%m-%d\")\n",
    "    df.index.name='date'\n",
    "    df['volume'] = df['volume'].astype(np.float64)\n",
    "    df['dividend'] =  df['dividend'].astype(np.float64)\n",
    "    df['split'] =  df['split'].astype(np.float64)\n",
    "    df.to_csv(path, header=True, index=True)\n",
    "    delay = randint(1,5) # random delay 1 to 5 sec \n",
    "    sleep(delay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Set Data Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify path if you would like to store the data elsewhere and change the notebooks accordingly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-21T07:53:30.220530Z",
     "start_time": "2022-11-21T07:53:30.214543Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_path = Path('data')\n",
    "if not results_path.exists():\n",
    "    results_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the csv path \n",
    "csv_path = Path('data/csv')\n",
    "if not csv_path.exists():\n",
    "    csv_path.mkdir(parents=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Nasdaq 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx_path_tmp = Path('data/csv/ndx/tmp')\n",
    "ndx_path = Path('data/csv/ndx/daily')\n",
    "if not ndx_path_tmp.exists() and not ndx_path.exists():\n",
    "    ndx_path_tmp.mkdir(parents=True)\n",
    "    ndx_path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download html table with Nasdaq 100 constituents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx_url = 'https://en.wikipedia.org/wiki/Nasdaq-100'\n",
    "nasdaq_constituents = pd.read_html(ndx_url, header=0)[4].rename(columns=str.lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>ticker</th>\n",
       "      <th>gics sector</th>\n",
       "      <th>gics sub-industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activision Blizzard</td>\n",
       "      <td>ATVI</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>Interactive Home Entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adobe Inc.</td>\n",
       "      <td>ADBE</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Application Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADP</td>\n",
       "      <td>ADP</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Data Processing &amp; Outsourced Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Airbnb</td>\n",
       "      <td>ABNB</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Internet &amp; Direct Marketing Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Align Technology</td>\n",
       "      <td>ALGN</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Supplies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company ticker             gics sector  \\\n",
       "0  Activision Blizzard   ATVI  Communication Services   \n",
       "1           Adobe Inc.   ADBE  Information Technology   \n",
       "2                  ADP    ADP  Information Technology   \n",
       "3               Airbnb   ABNB  Consumer Discretionary   \n",
       "4     Align Technology   ALGN             Health Care   \n",
       "\n",
       "                       gics sub-industry  \n",
       "0         Interactive Home Entertainment  \n",
       "1                   Application Software  \n",
       "2  Data Processing & Outsourced Services  \n",
       "3     Internet & Direct Marketing Retail  \n",
       "4                   Health Care Supplies  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nasdaq_constituents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_constituents.columns = ['company', 'ticker', 'sector', 'industry']\n",
    "nasdaq_constituents.to_csv('data/ndx_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = nasdaq_constituents.ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      ATVI\n",
       "1      ADBE\n",
       "2       ADP\n",
       "3      ABNB\n",
       "4      ALGN\n",
       "       ... \n",
       "96      WBD\n",
       "97     WDAY\n",
       "98      XEL\n",
       "99       ZM\n",
       "100      ZS\n",
       "Name: ticker, Length: 101, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data for Nasdaq Assets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download Prices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [05:46<00:00,  3.43s/it]\n"
     ]
    }
   ],
   "source": [
    "for ass in tqdm(assets):\n",
    "    try:\n",
    "        download_csv_data(symbol=ass, start_date=start.strftime(\"%Y-%m-%d\"), end_date=end.strftime(\"%Y-%m-%d\"), freq='daily', path='data/csv/ndx/tmp/'+ass+'.csv')\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for tick in tqdm(assets):\n",
    "    try:\n",
    "        path ='data/csv/ndx/tmp/'+tick+'.csv'\n",
    "        d = pd.read_csv(path, index_col=[0])\n",
    "        d.index = pd.DatetimeIndex(d.index)\n",
    "        d.index = d.index.strftime(\"%Y-%m-%d\")\n",
    "        d.to_csv(path, header=True, index=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:00<00:00, 159.39it/s]\n"
     ]
    }
   ],
   "source": [
    "out = []\n",
    "for tick in tqdm(assets):\n",
    "    try:\n",
    "        path='data/csv/ndx/tmp/'+tick+'.csv'\n",
    "        d=pd.read_csv(path, index_col=[0])\n",
    "        d.index.name='date'\n",
    "        d=d.reset_index()\n",
    "        cols = [(tick, col) for col in d.columns]\n",
    "        d['ticker'] = tick\n",
    "        d.set_index(['date', 'ticker'], inplace=True)\n",
    "        out.append(d)\n",
    "    except:\n",
    "        pass    \n",
    "    \n",
    "df_adj = pd.concat(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>dividend</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-11-04</th>\n",
       "      <th>ATVI</th>\n",
       "      <td>2.859375</td>\n",
       "      <td>2.906250</td>\n",
       "      <td>2.812500</td>\n",
       "      <td>2.872500</td>\n",
       "      <td>5360000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-11-05</th>\n",
       "      <th>ATVI</th>\n",
       "      <td>2.814375</td>\n",
       "      <td>2.915625</td>\n",
       "      <td>2.810625</td>\n",
       "      <td>2.836875</td>\n",
       "      <td>6768000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-11-06</th>\n",
       "      <th>ATVI</th>\n",
       "      <td>2.848125</td>\n",
       "      <td>2.870625</td>\n",
       "      <td>2.791875</td>\n",
       "      <td>2.805000</td>\n",
       "      <td>14337600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-11-07</th>\n",
       "      <th>ATVI</th>\n",
       "      <td>2.857500</td>\n",
       "      <td>2.994375</td>\n",
       "      <td>2.775000</td>\n",
       "      <td>2.919375</td>\n",
       "      <td>19839467.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-11-10</th>\n",
       "      <th>ATVI</th>\n",
       "      <td>2.872500</td>\n",
       "      <td>2.936250</td>\n",
       "      <td>2.829375</td>\n",
       "      <td>2.915625</td>\n",
       "      <td>10602667.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-21</th>\n",
       "      <th>ZS</th>\n",
       "      <td>130.210007</td>\n",
       "      <td>131.350006</td>\n",
       "      <td>127.342003</td>\n",
       "      <td>127.839996</td>\n",
       "      <td>1502200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-22</th>\n",
       "      <th>ZS</th>\n",
       "      <td>131.100006</td>\n",
       "      <td>133.449997</td>\n",
       "      <td>129.600006</td>\n",
       "      <td>132.160004</td>\n",
       "      <td>1886000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-23</th>\n",
       "      <th>ZS</th>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.425003</td>\n",
       "      <td>130.710007</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>1437000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-24</th>\n",
       "      <th>ZS</th>\n",
       "      <td>130.080002</td>\n",
       "      <td>132.490005</td>\n",
       "      <td>129.559998</td>\n",
       "      <td>130.880005</td>\n",
       "      <td>1659000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-27</th>\n",
       "      <th>ZS</th>\n",
       "      <td>133.119995</td>\n",
       "      <td>135.160004</td>\n",
       "      <td>131.479996</td>\n",
       "      <td>131.839996</td>\n",
       "      <td>1294700.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408852 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         open        high         low       close      volume  \\\n",
       "date       ticker                                                               \n",
       "2003-11-04 ATVI      2.859375    2.906250    2.812500    2.872500   5360000.0   \n",
       "2003-11-05 ATVI      2.814375    2.915625    2.810625    2.836875   6768000.0   \n",
       "2003-11-06 ATVI      2.848125    2.870625    2.791875    2.805000  14337600.0   \n",
       "2003-11-07 ATVI      2.857500    2.994375    2.775000    2.919375  19839467.0   \n",
       "2003-11-10 ATVI      2.872500    2.936250    2.829375    2.915625  10602667.0   \n",
       "...                       ...         ...         ...         ...         ...   \n",
       "2023-02-21 ZS      130.210007  131.350006  127.342003  127.839996   1502200.0   \n",
       "2023-02-22 ZS      131.100006  133.449997  129.600006  132.160004   1886000.0   \n",
       "2023-02-23 ZS      134.000000  134.425003  130.710007  133.500000   1437000.0   \n",
       "2023-02-24 ZS      130.080002  132.490005  129.559998  130.880005   1659000.0   \n",
       "2023-02-27 ZS      133.119995  135.160004  131.479996  131.839996   1294700.0   \n",
       "\n",
       "                   dividend  split  \n",
       "date       ticker                   \n",
       "2003-11-04 ATVI         0.0    1.0  \n",
       "2003-11-05 ATVI         0.0    1.0  \n",
       "2003-11-06 ATVI         0.0    1.0  \n",
       "2003-11-07 ATVI         0.0    1.0  \n",
       "2003-11-10 ATVI         0.0    1.0  \n",
       "...                     ...    ...  \n",
       "2023-02-21 ZS           0.0    1.0  \n",
       "2023-02-22 ZS           0.0    1.0  \n",
       "2023-02-23 ZS           0.0    1.0  \n",
       "2023-02-24 ZS           0.0    1.0  \n",
       "2023-02-27 ZS           0.0    1.0  \n",
       "\n",
       "[408852 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_adj.close.unstack('ticker')\n",
    "pmax = df.pct_change().max()\n",
    "pmin = df.pct_change().min()\n",
    "to_drop = pmax[pmax > 1].index.union(pmin[pmin<-1].index)\n",
    "len(to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_adj.drop(to_drop, level='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/ndx_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx_tickers = pd.DataFrame(df.index.unique('ticker'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx_tickers.to_csv(\"data/tickers/ndx_tickers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx_tickers = list(ndx_tickers.ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 101/101 [00:02<00:00, 48.20it/s]\n"
     ]
    }
   ],
   "source": [
    "# move data into final folder\n",
    "for tick in tqdm(ndx_tickers):\n",
    "    path_tmp = 'data/csv/ndx/tmp/'+tick+'.csv'\n",
    "    path = 'data/csv/ndx/daily/'+tick+'.csv'\n",
    "    df = pd.read_csv(path_tmp, index_col=[0])\n",
    "    fill_missing_values(df)\n",
    "    df.to_csv(path, header=True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zip39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6b15f53b134105f340d3a370e7f28e5f161b18f10443b548acbc587a2020db1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
